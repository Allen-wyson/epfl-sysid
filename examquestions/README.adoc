== System Identification - Exam Questions
:stem: latexmath

=== 1. Compare impulse, step, sum of sinusoids, discrete random processes and PRBS signals in terms of their spectra and their degrees of excitation.

* *Impulse*: Constant 1 spectrum and excitation in all frequencies,
infinite degree of excitation. The signal has very low energy as it
inputs zero energy everywhere except at latexmath:[k=0].
* *Step*: In theory the degree of excitation is also infinite. However, the step signal puts more energy in low frequency and the energy per frequency quickly decays over the frequency axis. In consequence if a system is excited by a step signal, very low frequencies and the DC part are strongly excited while high frequency are approximately not excited at all.
* *Sum of Sinusoids*: The degree of excitation is n, where n is the number of sinusoids summed. The spectrum is discrete and hand specific peaks at the frequencies of the summed sinusoids.
* *Discrete Random Processes*: Discrete random processes have also infinite degree of excitation as the spectrum is continuous. The spectrum depends on the covariance of the noise.
* *PRBS*: The signal is periodic and the spectrum is therefore discrete and the degree of excitation is finite. The spectrum of a pure (non-divided) PRBS signal is flat and it can be shaped using frequency dividers.

=== 2. How can we find the impulse response of a system using the correlation approach?

The system is excited with a suitable input signal and the response of the system is recorded. Then, the autocorrelation of the input signal and the cross-correlation of the input and response signal is estimated.
In order to compute the estimate for the impulse response latexmath:[g(h)], one of the following approaches is used dependent on whether the input signal is white or not.
For white noise latexmath:[g(h) = \frac{\hat{R}_{yu}(h)}{\hat{R}_{uu}(0)}], else if the input signal is not white numerical deconvolution using the following relation:
[latexmath]
+++++++++++
R_{yu}(h) = \sum\limits_{j=0}^{K-1} g(j) R_{uu}(h - j)
+++++++++++
In the above equations latexmath:[\hat{R}_{uu}] denote the estimated autocorrelation of the input signal and latexmath:[\hat{R}_{yu}] denotes the estimated cross-correlation between the input and output signal.

=== 3. How is a PRBS generated? What is the period of a PRBS? How can its richness at low frequencies be improved?

image:prbs.png[PRBS]

the (maximum) period is latexmath:[M = 2^n - 1]. For richer signal at low frequencies: add a frequency divider between the PRBS generator and the test system.

=== 4. Explain the principle of bias-variance trade-off in estimation problems.

The bias-variance trade-off is present in all estimation problems with noisy data. Basically, the intuition is when the model capacity is low (low amount of parameters) the model has not enough capacity to fit the data and there will be always some error due to the modelling with a low capacity model called *bias*. At the same time for reasonable assumptions on the noise the variance of the parameter estimates will be low as the system will be highly overdetermined. On the other hand, when the model capacity is large, the model has enough capacity to fit the data and the bias is low.
However, at larger model capacities also the *variance* in the parameter estimates is higher as the estimates stronger respond to the noise realization. We can decompose the fit-error into variance, bias and noise, where bias and variance depend on the model chosen and the noise term is constant.

=== 5. Explain the principle of Fourier analysis. Name three major errors in Fourier analysis. Explain how the truncation error can be reduced.

The objective of Fourier analysis is to identify the frequency response latexmath:[G(j\omega)] of the test system. Therefore, test signal is applied to the test system and the recorded system response is analyzed.
[latexmath]
+++++++++++
G(j\omega) = \frac{Y(j\omega)}{U(j\omega)}
+++++++++++

==== Errors are:
* *Sampling Error:* we identify latexmath:[G(e^{j\omega})] instead of latexmath:[G(j\omega)]
* *Measurement Error:* the measured output is not the true output
* *Truncation Error:* The Fourier transform uses and infinite sum. We use a finite one.

==== Reduction of Truncation Error
* excitation with energy signal and wait for transience to vanish after the end of the signal
* periodic signal -> no truncation error
* windowing

=== 6. Explain how the frequency response can be identified using the spectral analysis method. How can the estimates be improved by averaging? How can the estimates be improved with windowing? Discuss the choice of the window's width.

In contrast to the Fourier analysis, the spectral analysis method is not based on the Fourier transforms of the in- and output signal, but on their auto- and cross-correlation function, respectively. So in other word the power spectral densities are used in order to estimate the frequency response of the test system using the relation
[latexmath]
+++++++++++
G(e^{j\omega_n}) = \frac{\Phi_{yu}(\omega_n)}{\Phi_{uu}(\omega_n)}
+++++++++++
where latexmath:[\Phi_{yu}(\omega_n) = \sum\limits_{h=0}^{N-1} \hat{R}_{yu} e^{-jh \frac{2\pi n}{N}}] for latexmath:[\omega_n = \frac{n \omega_s}{N}].

By using less frequency bins, the available data can be split to compute the less-resolution outcome of the spectral analysis of subsequences of the data. Then, the results of multiple runs can be averaged to reduce the effect of noise. Averaging is done on the power spectral density functions, no on latexmath:[G(e^{j\omega})]. The estimates of the auto- and cross-correlation functions are usually the more inaccurate the more you move away from h=0. Therefore, a windowing function filtering out the less-accurate parts of the correlation functions can be used to improve the results of the spectral analysis method. The window should b as small as possible to filter out the inaccurate parts, but not too small to minimize the effect of spectrum-smearing by the Fourier-transform of the window.

=== 7. Why are we interested in closed-loop identification? What is the major problem? How can a good model be obtained by spectral analysis?
There are certain points why we would perform a closed-loop identification. There is a class of instable systems that is stabilized in closed-loop operation with a controller. (Think of applying PRBS in open-loop operation to an inverse pendulum ;)) Also, there exist systems with integrators creating an output drift in open-loop. Also, when identifying a system in closed-loop it is excited in the frequencies relevant for controller design, so we concentrate the frequency distribution of the system excitation during data acquisition in the relevant region, automatically.

The main problem in closed-loop is, that the input of the test system is correlated with feedback and spectral analysis can therefore not be applied directly.
The identified model resulting from closed-loop identification may be appropriate for controller design, but in general it might not be very useful for other tasks like simulation or gaining physical insight in the model structure.

=== 8. Define the ARX structure with a block diagram. Discuss its properties (fit criterion, biasedness, optimization, bias distribution).

image:arx.png[ARX]

=== 9. Define the ARMAX structure with a block diagram. Discuss its properties (fit criterion, biasedness, optimization, bias distribution).

image:armax.png[ARMAX]

=== 10. Define the OE structure with a block diagram. Discuss its properties (fit criterion, biasedness, optimization, bias distribution).

image:oe.png[OE]

=== 11. Define the BJ structure with a block diagram. Discuss its properties (fit criterion, biasedness, optimization, bias distribution).

image:bj.png[BJ]

=== 12. Explain the principle of the IV method to obtain asymptotically unbiased estimates. How can the IV vector be chosen?

=== 13. Explain the different steps of the state-space identification method: when are the states measured and when are they estimated using the subspace projection method.

=== 14. Explain the different steps of the subspace identification method based on the observability matrix: estimation of the extended observability matrix, estimation of the order n, the matrices A and C, and estimation of B and D.

=== 15. Explain the Gauss-Newton method for minimization of the fit criterion.

=== 16. Explain the pseudo linear regression algorithm to solve nonlinear optimization problems.

=== 17. Explain the principles of the recursive identification algorithms. What is the forgetting factor?

=== 18. Explain what the bias distribution is and why it is important.

=== 19. Explain the direct and indirect methods for closed-loop identification.

=== 20. What is the cross-correlation test? What is the whiteness test? How are the confidence intervals computed?
